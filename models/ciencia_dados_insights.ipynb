{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57de4b9f",
   "metadata": {},
   "source": [
    "\n",
    "# ciência_de_dados_insights.ipynb\n",
    "\n",
    "Notebook preparado para rodar localmente (ou no Google Colab). Objetivos:\n",
    "- Calcular RFM e gerar clusters de clientes (K-Means)\n",
    "- Prever vendas mensais (Holt-Winters)\n",
    "- Exportar resultados para uso no Power BI (`data/clientes_clusters.csv`, `data/previsao_vendas.csv`)\n",
    "\n",
    "**Observações**:\n",
    "- Os arquivos CSV originais devem estar em `/mnt/data/` (já enviados por você):  \n",
    "  `vendas_2023_2025.csv`, `clientes.csv`, `itens_venda.csv`, `produtos.csv`\n",
    "- No Colab, faça upload dos CSVs para o ambiente ou monte o Google Drive.\n",
    "- Se usar Prophet, instale `prophet` — aqui usamos `statsmodels` (Holt-Winters) para evitar dependências extras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup e imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelagem / clustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Forecasting\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Anomaly detection (opcional)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Paths (ajuste se necessário)\n",
    "PATH_VENDAS = '/mnt/data/vendas_2023_2025.csv'\n",
    "PATH_CLIENTES = '/mnt/data/clientes.csv'\n",
    "PATH_ITENS = '/mnt/data/itens_venda.csv'\n",
    "PATH_PRODUTOS = '/mnt/data/produtos.csv'\n",
    "\n",
    "print('Bibliotecas importadas.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9083f",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Carregar dados\n",
    "Certifique-se de que os CSVs estejam nos caminhos acima. As colunas esperadas (resumo):\n",
    "- `vendas_2023_2025.csv`: venda_id, cliente_id, data_venda, total_venda, ...\n",
    "- `clientes.csv`: cliente_id, nome, email, cidade, estado, data_cadastro, ...\n",
    "- `itens_venda.csv`: item_id, venda_id, produto_id, quantidade, preco_unitario, total_item\n",
    "- `produtos.csv`: produto_id, nome, categoria, preco, custo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregar CSVs (com parsing de datas onde aplicável)\n",
    "vendas = pd.read_csv(PATH_VENDAS, parse_dates=['data_venda'], dayfirst=False, infer_datetime_format=True)\n",
    "clientes = pd.read_csv(PATH_CLIENTES)\n",
    "itens = pd.read_csv(PATH_ITENS)\n",
    "produtos = pd.read_csv(PATH_PRODUTOS)\n",
    "\n",
    "print('Linhas carregadas:')\n",
    "print('vendas:', vendas.shape)\n",
    "print('clientes:', clientes.shape)\n",
    "print('itens:', itens.shape)\n",
    "print('produtos:', produtos.shape)\n",
    "\n",
    "# Merge para um dataframe analítico (cada item de venda em uma linha)\n",
    "df = (vendas.merge(clientes, on='cliente_id', how='left', suffixes=('','_cliente'))\n",
    "        .merge(itens, on='venda_id', how='left', suffixes=('','_item'))\n",
    "        .merge(produtos, on='produto_id', how='left', suffixes=('','_produto')))\n",
    "\n",
    "print('Dataframe combinado df:', df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb86054",
   "metadata": {},
   "source": [
    "\n",
    "## 2. RFM (Recency, Frequency, Monetary) e K-Means\n",
    "\n",
    "- **Recency**: dias desde a última compra (utilizamos snapshot = data máxima das vendas + 1 dia)\n",
    "- **Frequency**: número de compras (vendas) por cliente\n",
    "- **Monetary**: soma do valor gasto por cliente\n",
    "\n",
    "Depois normalizamos e aplicamos K-Means para segmentação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520445c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RFM\n",
    "snapshot = vendas['data_venda'].max() + pd.Timedelta(days=1)\n",
    "print('Snapshot (data referência):', snapshot.date())\n",
    "\n",
    "# Frequency: contar vendas distintas por cliente\n",
    "frequency = vendas.groupby('cliente_id')['venda_id'].nunique().rename('Frequency')\n",
    "# Recency: dias desde última compra\n",
    "recency = vendas.groupby('cliente_id')['data_venda'].max().apply(lambda x: (snapshot - x).days).rename('Recency')\n",
    "# Monetary: soma total_venda por cliente\n",
    "monetary = vendas.groupby('cliente_id')['total_venda'].sum().rename('Monetary')\n",
    "\n",
    "rfm = pd.concat([recency, frequency, monetary], axis=1).reset_index()\n",
    "rfm.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparar para K-Means: transformação log (para Monetary) e padronização\n",
    "rfm_clean = rfm.copy()\n",
    "rfm_clean['Monetary_log'] = np.log1p(rfm_clean['Monetary'])\n",
    "features = ['Recency','Frequency','Monetary_log']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(rfm_clean[features])\n",
    "\n",
    "# Escolher k com elbow (rápido)\n",
    "sse = []\n",
    "K = range(2,7)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X)\n",
    "    sse.append(km.inertia_)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(K, sse, '-o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('SSE (inertia)')\n",
    "plt.title('Elbow method (k selection)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Definimos k=4 (ajuste conforme o elbow)\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "rfm_clean['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Mapear cluster para rótulos qualitativos (exemplo)\n",
    "cluster_order = rfm_clean.groupby('Cluster')['Monetary'].median().sort_values(ascending=False).index.tolist()\n",
    "label_map = {cluster_order[0]: 'VIP', cluster_order[1]: 'Loyal', cluster_order[2]: 'Occasional', cluster_order[3]: 'At Risk'}\n",
    "rfm_clean['Cluster_Label'] = rfm_clean['Cluster'].map(label_map)\n",
    "\n",
    "rfm_clean[['cliente_id','Recency','Frequency','Monetary','Cluster','Cluster_Label']].head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d731d",
   "metadata": {},
   "source": [
    "\n",
    "### Exportar clusters para Power BI\n",
    "O arquivo `data/clientes_clusters.csv` será consumido no Power BI (crie uma página \"Customer Segments\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f665ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Garantir pasta data/\n",
    "os.makedirs('/mnt/data', exist_ok=True)\n",
    "rfm_out = rfm_clean[['cliente_id','Recency','Frequency','Monetary','Cluster','Cluster_Label']].copy()\n",
    "# Se quiser, juntar colunas de nome do cliente\n",
    "rfm_out = rfm_out.merge(clientes[['cliente_id','nome','cidade','estado']], on='cliente_id', how='left')\n",
    "rfm_out.to_csv('/mnt/data/clientes_clusters.csv', index=False)\n",
    "print('Exportado: /mnt/data/clientes_clusters.csv (linhas = {})'.format(len(rfm_out)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771418aa",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Previsão de Vendas Mensais (Holt-Winters)\n",
    "\n",
    "- Agrupamos vendas por mês (soma de `total_venda`) e aplicamos ExponentialSmoothing (Holt-Winters) com sazonalidade anual (12 meses).\n",
    "- Exportamos previsão para uso no Power BI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d06bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agrupar vendas por mês\n",
    "mensal = vendas.set_index('data_venda').resample('M')['total_venda'].sum().rename('y')\n",
    "mensal = mensal.to_frame().reset_index()\n",
    "mensal.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ajustar Holt-Winters com sazonalidade aditiva (12 meses)\n",
    "ts = mensal.copy()\n",
    "ts = ts.set_index('data_venda').asfreq('M')\n",
    "ts['y'] = ts['y'].fillna(0)\n",
    "\n",
    "model = ExponentialSmoothing(ts['y'], trend='add', seasonal='add', seasonal_periods=12, initialization_method='estimated')\n",
    "fit = model.fit(optimized=True)\n",
    "\n",
    "# Previsão para próximos 6 meses\n",
    "future_periods = 6\n",
    "forecast_index = pd.date_range(start=ts.index[-1] + pd.offsets.MonthBegin(1), periods=future_periods, freq='M')\n",
    "forecast_vals = fit.forecast(future_periods)\n",
    "\n",
    "forecast_df = pd.DataFrame({'ds': forecast_index, 'yhat': forecast_vals.values}).reset_index(drop=True)\n",
    "\n",
    "# Combine histórico + forecast for plotting\n",
    "hist_df = ts.reset_index().rename(columns={'data_venda':'ds','y':'y'})\n",
    "plot_df = pd.concat([hist_df.tail(36), forecast_df], ignore_index=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,3.5))\n",
    "plt.plot(hist_df['ds'], hist_df['y'], label='Histórico')\n",
    "plt.plot(forecast_df['ds'], forecast_df['yhat'], label='Previsão', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Vendas Mensais - Histórico e Previsão (6 meses)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Export forecast CSV\n",
    "forecast_out = forecast_df[['ds','yhat']].copy()\n",
    "forecast_out.to_csv('/mnt/data/previsao_vendas.csv', index=False)\n",
    "print('Exportado: /mnt/data/previsao_vendas.csv (linhas = {})'.format(len(forecast_out)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbee380",
   "metadata": {},
   "source": [
    "\n",
    "## 4. (Opcional) Detecção de Anomalias nas Transações\n",
    "Usamos IsolationForest em features simples (total_item, preco_unitario) para sinalizar vendas possivelmente atípicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparar amostra de transações (itens)\n",
    "itens_sample = df[['venda_id','item_id','quantidade','preco_unitario','total_item','data_venda']].dropna()\n",
    "\n",
    "# Features para isolation forest: total_item e quantidade (poderá ajustar)\n",
    "X_anom = itens_sample[['quantidade','total_item']].copy()\n",
    "iso = IsolationForest(contamination=0.002, random_state=42)\n",
    "itens_sample['anomaly_score'] = iso.fit_predict(X_anom)\n",
    "# -1 -> anomalia, 1 -> normal\n",
    "anomalies = itens_sample[itens_sample['anomaly_score'] == -1].sort_values('total_item', ascending=False).head(20)\n",
    "anomalies[['venda_id','item_id','quantidade','total_item']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfcd66d",
   "metadata": {},
   "source": [
    "\n",
    "## Próximos passos / Integração com Power BI\n",
    "\n",
    "- Importe `/mnt/data/clientes_clusters.csv` para criar páginas de **Segmentação de Clientes**.\n",
    "- Importe `/mnt/data/previsao_vendas.csv` e combine com a série histórica para visualizar previsões.\n",
    "- Adicione slicers (Ano, Categoria, Estado) e cards com KPIs (ticket médio, vendas totais, clientes ativos).\n",
    "- Salve o notebook em `notebooks/` e faça commit no repositório GitHub.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
